{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00166693",
   "metadata": {},
   "source": [
    "# Analysing Data Scientist Salaries\n",
    "\n",
    "In this notebook, we will analyze the [Kaggle Jobs Dataset from Glassdoor](https://www.kaggle.com/datasets/thedevastator/jobs-dataset-from-glassdoor) that contains job postings from Glassdoor.com from 2017. \n",
    "\n",
    "We aim to analyze the dataset considering the following research questions:\n",
    "\n",
    "- What are the key factors that affect data science salaries? \n",
    "- Can we predict the salary of data science positions based on the job postings?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3e679",
   "metadata": {},
   "source": [
    "## Setup the dataset to HDFS for big data analysis\n",
    "\n",
    "The HDFS will allow us to store and retrieve the data efficiently for our analysis. It makes sure the data is readily available in parallel.\n",
    "\n",
    "Before loading the data to HDFS we added the missing header **ID** into files `eda_data.csv` and `glassdoor_jobs.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e334f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SET UP COMMANDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace5950",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb37d003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/23 11:59:48 WARN Utils: Your hostname, MacBook-Pro-Eric.local resolves to a loopback address: 127.0.0.1; using 213.112.119.200 instead (on interface en0)\n",
      "24/10/23 11:59:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/23 11:59:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "conf = SparkConf().set('spark.ui.port', '4040')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.appName('Data Scientist Salaries').master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078fccba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c-213-112-119-200.bbcust.telenor.se:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13a2f5a50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b4a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/23 11:59:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+------+--------------------+---------------+--------------+--------------------+-------+------------------+--------------------+--------------------+--------------------+--------------------+------+-----------------+----------+----------+----------+--------------------+---------+----------+---+---------+----+-----+---+-----+--------------+---------+--------+--------+\n",
      "| ID|           Job Title|     Salary Estimate|     Job Description|Rating|        Company Name|       Location|  Headquarters|                Size|Founded| Type of ownership|            Industry|              Sector|             Revenue|         Competitors|hourly|employer_provided|min_salary|max_salary|avg_salary|         company_txt|job_state|same_state|age|python_yn|R_yn|spark|aws|excel|      job_simp|seniority|desc_len|num_comp|\n",
      "+---+--------------------+--------------------+--------------------+------+--------------------+---------------+--------------+--------------------+-------+------------------+--------------------+--------------------+--------------------+--------------------+------+-----------------+----------+----------+----------+--------------------+---------+----------+---+---------+----+-----+---+-----+--------------+---------+--------+--------+\n",
      "|  0|      Data Scientist|$53K-$91K (Glassd...|Data Scientist\\nL...|   3.8|Tecolote Research...|Albuquerque, NM|    Goleta, CA|501 to 1000 emplo...|   1973| Company - Private| Aerospace & Defense| Aerospace & Defense|$50 to $100 milli...|                  -1|     0|                0|        53|        91|      72.0|   Tecolote Research|       NM|         0| 47|        1|   0|    0|  0|    1|data scientist|       na|    2536|       0|\n",
      "|  1|Healthcare Data S...|$63K-$112K (Glass...|What You Will Do:...|   3.4|University of Mar...|  Linthicum, MD| Baltimore, MD|    10000+ employees|   1984|Other Organization|Health Care Servi...|         Health Care|$2 to $5 billion ...|                  -1|     0|                0|        63|       112|      87.5|University of Mar...|       MD|         0| 36|        1|   0|    0|  0|    0|data scientist|       na|    4783|       0|\n",
      "|  2|      Data Scientist|$80K-$90K (Glassd...|KnowBe4, Inc. is ...|   4.8|        KnowBe4\\n4.8| Clearwater, FL|Clearwater, FL|501 to 1000 emplo...|   2010| Company - Private|   Security Services|   Business Services|$100 to $500 mill...|                  -1|     0|                0|        80|        90|      85.0|             KnowBe4|       FL|         1| 10|        1|   0|    1|  0|    1|data scientist|       na|    3461|       0|\n",
      "|  3|      Data Scientist|$56K-$97K (Glassd...|*Organization and...|   3.8|           PNNL\\n3.8|   Richland, WA|  Richland, WA|1001 to 5000 empl...|   1965|        Government|              Energy|Oil, Gas, Energy ...|$500 million to $...|Oak Ridge Nationa...|     0|                0|        56|        97|      76.5|                PNNL|       WA|         1| 55|        1|   0|    0|  0|    0|data scientist|       na|    3883|       3|\n",
      "|  4|      Data Scientist|$86K-$143K (Glass...|Data Scientist\\nA...|   2.9|Affinity Solution...|   New York, NY|  New York, NY| 51 to 200 employees|   1998| Company - Private|Advertising & Mar...|   Business Services|Unknown / Non-App...|Commerce Signals,...|     0|                0|        86|       143|     114.5|  Affinity Solutions|       NY|         1| 22|        1|   0|    0|  0|    1|data scientist|       na|    2728|       3|\n",
      "+---+--------------------+--------------------+--------------------+------+--------------------+---------------+--------------+--------------------+-------+------------------+--------------------+--------------------+--------------------+--------------------+------+-----------------+----------+----------+----------+--------------------+---------+----------+---+---------+----+-----+---+-----+--------------+---------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the dataset, ecape quotes inside the job descriptions\n",
    "df = spark.read.csv('./dataset/eda_data.csv', header=True, inferSchema=True, multiLine=True, quote='\"', escape='\"', mode='PERMISSIVE')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56dbff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 742\n",
      "Number of columns: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Number of datapoints:', df.count())\n",
    "print('Number of columns:', len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5d126",
   "metadata": {},
   "source": [
    "**Show schema:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0c7b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      " |-- Salary Estimate: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Company Name: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Headquarters: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Founded: integer (nullable = true)\n",
      " |-- Type of ownership: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- Revenue: string (nullable = true)\n",
      " |-- Competitors: string (nullable = true)\n",
      " |-- hourly: integer (nullable = true)\n",
      " |-- employer_provided: integer (nullable = true)\n",
      " |-- min_salary: integer (nullable = true)\n",
      " |-- max_salary: integer (nullable = true)\n",
      " |-- avg_salary: double (nullable = true)\n",
      " |-- company_txt: string (nullable = true)\n",
      " |-- job_state: string (nullable = true)\n",
      " |-- same_state: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- python_yn: integer (nullable = true)\n",
      " |-- R_yn: integer (nullable = true)\n",
      " |-- spark: integer (nullable = true)\n",
      " |-- aws: integer (nullable = true)\n",
      " |-- excel: integer (nullable = true)\n",
      " |-- job_simp: string (nullable = true)\n",
      " |-- seniority: string (nullable = true)\n",
      " |-- desc_len: integer (nullable = true)\n",
      " |-- num_comp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e859655",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "First, we will fix our dataset with regard to missing values and either fill the instances or drop the records containing these values.\n",
    "\n",
    "**Handling of irrelevant features:**\n",
    "\n",
    "The dataset contains a lot of columns that are interesting and could be used for the predicitons.  We have decided to drop features that will not be necessary for our analysis, from the data set, to decrease dimensionality and also the number of missing values that need to be filled. Since the `Job Description` column contains a long string of text we choose to drop and use `desc_len` as an inidicator of how detailed the descriptions for each job are. We also do not care about where a single person wants to work or their feature so we drop columns `same_state` and `age`. `Company Name`is just an unclean version of `company_txt`, and `Salary Estimate` is already diveded to `min_salary`, `avg_salary` and `max_salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b8f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_irrelevant_cols(df):\n",
    "    df = df.drop(*['Job Description', 'age', 'same_state', 'Competitors', 'Company Name', 'Salary Estimate'])\n",
    "    return df\n",
    "\n",
    "df = drop_irrelevant_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895a1842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-------+-----------------+-----------------+---------+----------------+--------------------+-------------------+--------------------+-----------------+------------------+------------------+--------------------+---------+-------------------+--------------------+-------------------+-------------------+-------------------+--------+---------+------------------+------------------+\n",
      "|summary|                ID|        Job Title|            Rating|        Location|       Headquarters|   Size|          Founded|Type of ownership| Industry|          Sector|             Revenue|             hourly|   employer_provided|       min_salary|        max_salary|        avg_salary|         company_txt|job_state|          python_yn|                R_yn|              spark|                aws|              excel|job_simp|seniority|          desc_len|          num_comp|\n",
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-------+-----------------+-----------------+---------+----------------+--------------------+-------------------+--------------------+-----------------+------------------+------------------+--------------------+---------+-------------------+--------------------+-------------------+-------------------+-------------------+--------+---------+------------------+------------------+\n",
      "|  count|               742|              742|               742|             742|                742|    742|              742|              742|      742|             742|                 742|                742|                 742|              742|               742|               742|                 742|      742|                742|                 742|                742|                742|                742|     742|      742|               742|               742|\n",
      "|   mean|             370.5|             NULL|3.6188679245283057|            NULL|               -1.0|   -1.0|1837.154986522911|             -1.0|     -1.0|            -1.0|                -1.0|0.03234501347708895|0.022911051212938006|74.71967654986523|128.14959568733153|100.62601078167116|                NULL|     NULL| 0.5283018867924528|0.002695417789757...|0.22506738544474394| 0.2371967654986523|  0.522911051212938|    NULL|     NULL| 3869.545822102426|1.0539083557951483|\n",
      "| stddev|214.34123883813555|             NULL|0.8012101584634994|            NULL|               NULL|   NULL|497.1837627029657|             NULL|      0.0|             0.0|                NULL|0.17703404247509585| 0.14972089250897577|30.98059321850606|45.220324256712196|38.855948156512454|                NULL|     NULL|0.49953508800982177| 0.05188236934528476|0.41790840066994306|0.42565083812312854|0.49981172181094585|    NULL|     NULL|1521.4958678994672| 1.384239252217433|\n",
      "|    min|                 0|Ag Data Scientist|              -1.0|Agoura Hills, CA|                 -1|     -1|               -1|               -1|       -1|              -1|$1 to $2 billion ...|                  0|                   0|               15|                16|              13.5|1-800-FLOWERS.COM...|       AL|                  0|                   0|                  0|                  0|                  0| analyst|       jr|               407|                 0|\n",
      "|    max|               741| Web Data Analyst|               5.0|   Worcester, MA|Zurich, Switzerland|Unknown|             2019|          Unknown|Wholesale|Travel & Tourism|Unknown / Non-App...|                  1|                   1|              202|               306|             254.0|           webfx.com|       WI|                  1|                   1|                  1|                  1|                  1|      na|   senior|             10051|                 4|\n",
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-------+-----------------+-----------------+---------+----------------+--------------------+-------------------+--------------------+-----------------+------------------+------------------+--------------------+---------+-------------------+--------------------+-------------------+-------------------+-------------------+--------+---------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ac59b",
   "metadata": {},
   "source": [
    "**Handling missing values:**\n",
    "\n",
    "The dataset uses value `-1` to indicate missing values on most columns, which is also visible in the dataset description above showing the summaries per column. We will deal with these column by column case, and fill them with actual data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94000591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: [('Rating', 11), ('Headquarters', 1), ('Size', 1), ('Founded', 50), ('Type of ownership', 1), ('Industry', 10), ('Sector', 10), ('Revenue', 1)]\n"
     ]
    }
   ],
   "source": [
    "cols_missing_values = []\n",
    "for col in df.columns:\n",
    "    missing_count = df.filter(F.col(col) == -1).count()\n",
    "    if missing_count > 0:\n",
    "        cols_missing_values.append((col, missing_count))\n",
    "\n",
    "print(\"Columns with missing values:\", cols_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f51571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+-------------+------------+----+-------+-----------------+--------+------+-------+------+-----------------+----------+----------+----------+--------------------+---------+---------+----+-----+---+-----+--------+---------+--------+--------+\n",
      "| ID|           Job Title|Rating|     Location|Headquarters|Size|Founded|Type of ownership|Industry|Sector|Revenue|hourly|employer_provided|min_salary|max_salary|avg_salary|         company_txt|job_state|python_yn|R_yn|spark|aws|excel|job_simp|seniority|desc_len|num_comp|\n",
      "+---+--------------------+------+-------------+------------+----+-------+-----------------+--------+------+-------+------+-----------------+----------+----------+----------+--------------------+---------+---------+----+-----+---+-----+--------+---------+--------+--------+\n",
      "|581|Scientist â€“ Cance...|  -1.0|Cambridge, MA|          -1|  -1|     -1|               -1|      -1|    -1|     -1|     0|                1|       100|       135|     117.5|Monte Rosa Therap...|       MA|        0|   0|    0|  0|    1|      na|       na|    3437|       0|\n",
      "+---+--------------------+------+-------------+------------+----+-------+-----------------+--------+------+-------+------+-----------------+----------+----------+----------+--------------------+---------+---------+----+-----+---+-----+--------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after playing around with the data by checking the following condition for each column above, \n",
    "# it seems that one of the records seem to have many missing values, so we drop it\n",
    "bad_record = df.filter(df['Headquarters'] == -1)\n",
    "bad_record.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998fbf48",
   "metadata": {},
   "source": [
    "Drop the corrputed sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8410b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-----------------+------------------+--------------------+---------+----------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+---------+------------------+--------------------+-------------------+-------------------+------------------+--------+---------+------------------+------------------+\n",
      "|summary|                ID|        Job Title|            Rating|        Location|       Headquarters|             Size|           Founded|   Type of ownership| Industry|          Sector|             Revenue|              hourly|   employer_provided|        min_salary|        max_salary|        avg_salary|         company_txt|job_state|         python_yn|                R_yn|              spark|                aws|             excel|job_simp|seniority|          desc_len|          num_comp|\n",
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-----------------+------------------+--------------------+---------+----------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+---------+------------------+--------------------+-------------------+-------------------+------------------+--------+---------+------------------+------------------+\n",
      "|  count|               741|              741|               741|             741|                741|              741|               741|                 741|      741|             741|                 741|                 741|                 741|               741|               741|               741|                 741|      741|               741|                 741|                741|                741|               741|     741|      741|               741|               741|\n",
      "|   mean| 370.2159244264507|             NULL|3.6251012145749026|            NULL|               NULL|             NULL|1839.6356275303644|                NULL|     -1.0|            -1.0|                NULL|0.032388663967611336|0.021592442645074223|  74.6855600539811|  128.140350877193|100.60323886639677|                NULL|     NULL|0.5290148448043185|0.002699055330634278| 0.2253711201079622|0.23751686909581646|0.5222672064777328|    NULL|     NULL|3870.1295546558704|1.0553306342780027|\n",
      "| stddev|214.34619462793214|             NULL|0.7835410934642616|            NULL|               NULL|             NULL| 492.9032463846545|                NULL|      0.0|             0.0|                NULL|  0.1771496239813286|  0.1454467531327641|30.987568027957078|45.250166544546005| 38.87723839435158|                NULL|     NULL|0.4994945835227074| 0.05191731848396881|0.41810871297729174|0.42584896294587343|0.4998413141338195|    NULL|     NULL|1522.4404135868954|1.3846315950630184|\n",
      "|    min|                 0|Ag Data Scientist|              -1.0|Agoura Hills, CA|          Akron, OH|1 to 50 employees|                -1|College / University|       -1|              -1|$1 to $2 billion ...|                   0|                   0|                15|                16|              13.5|1-800-FLOWERS.COM...|       AL|                 0|                   0|                  0|                  0|                 0| analyst|       jr|               407|                 0|\n",
      "|    max|               741| Web Data Analyst|               5.0|   Worcester, MA|Zurich, Switzerland|          Unknown|              2019|             Unknown|Wholesale|Travel & Tourism|Unknown / Non-App...|                   1|                   1|               202|               306|             254.0|           webfx.com|       WI|                 1|                   1|                  1|                  1|                 1|      na|   senior|             10051|                 4|\n",
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-----------------+------------------+--------------------+---------+----------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+---------+------------------+--------------------+-------------------+-------------------+------------------+--------+---------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.filter(df['ID'] != 581)\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c963d",
   "metadata": {},
   "source": [
    "Check again after dropping faulty sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be88cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: [('Rating', 10), ('Founded', 49), ('Industry', 9), ('Sector', 9)]\n"
     ]
    }
   ],
   "source": [
    "cols_missing_values = []\n",
    "for col in df.columns:\n",
    "    missing_count = df.filter(F.col(col) == -1).count()\n",
    "    if missing_count > 0:\n",
    "        cols_missing_values.append((col, missing_count))\n",
    "\n",
    "print(\"Columns with missing values:\", cols_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78644d1",
   "metadata": {},
   "source": [
    "The `Rating`is a value in range $[0, 5]$, `Founded` corresponds to a year, `Industry` and `Sector` are categoricals that already have a variable for value *Unknown*. \n",
    "\n",
    "For `Rating` we decided that assuming the mean is reasonable for missing values, and for `Founded` the median (most common year). For `Industry` and `Sector` we can use the already defined *Unknown* value to fill the `-1`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49fecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+\n",
      "|min_value|max_value|median_value|\n",
      "+---------+---------+------------+\n",
      "|     1744|     2019|        1992|\n",
      "+---------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the median, max and min of the founded column\n",
    "min_max_median = df.filter(df['Founded'] != -1).agg(\n",
    "    F.min('Founded').alias('min_value'),\n",
    "    F.max('Founded').alias('max_value'),\n",
    "    F.expr('percentile_approx(Founded, 0.5)').alias('median_value')  # 0.5 for median\n",
    ")\n",
    "\n",
    "min_max_median.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1112105",
   "metadata": {},
   "source": [
    "With further exploration we found missing values (`-1`or `na`) per column accordingly:\n",
    "\n",
    "- Rating - 11  -> `3` (mean)\n",
    "- Industry - `9`\n",
    "- Sector - 9 -> `Unknown`\n",
    "- Founded - 49 -> `1992` (median)\n",
    "- seniority - 519 -> `med` (medium experience)\n",
    "- job_simp - 183 -> `vague` (not a specific datascience role but more vague such as research scientist)\n",
    "\n",
    "\n",
    "The arrow points out the value to be used as the filler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4731ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df):\n",
    "    df = df.withColumn('Rating', F.when(df['Rating'] == -1, 3.0).otherwise(df['Rating']))  # use the mean\n",
    "    df = df.withColumn('Industry', F.when(df['Industry'] == -1, 'Unknown').otherwise(df['Industry']))  # the column already has a label Unknown so we use it\n",
    "    df = df.withColumn('Founded', F.when(df['Founded'] == -1, 1992).otherwise(df['Founded']))  # fill in median year founded\n",
    "\n",
    "    # change the na of seniotrity to mean mediocare experience requirements\n",
    "    df = df.withColumn('seniority', F.when(df['seniority'] == 'na', 'med').otherwise(df['seniority'])) \n",
    "    # not a clearly deined job position, research or scientist positons, devops/spark engineers or many tasks etc\n",
    "    df = df.withColumn('job_simp', F.when(df['job_simp'] == 'na', 'vague').otherwise(df['job_simp'])) \n",
    "    return df\n",
    "\n",
    "df = fill_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d400871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      job_simp|count|\n",
      "+--------------+-----+\n",
      "|data scientist|  279|\n",
      "|         vague|  183|\n",
      "|      director|   14|\n",
      "|       manager|   22|\n",
      "| data engineer|  119|\n",
      "|       analyst|  102|\n",
      "|           mle|   22|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job_simp').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d42722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'int'),\n",
       " ('Job Title', 'string'),\n",
       " ('Rating', 'double'),\n",
       " ('Location', 'string'),\n",
       " ('Headquarters', 'string'),\n",
       " ('Size', 'string'),\n",
       " ('Founded', 'int'),\n",
       " ('Type of ownership', 'string'),\n",
       " ('Industry', 'string'),\n",
       " ('Sector', 'string'),\n",
       " ('Revenue', 'string'),\n",
       " ('hourly', 'int'),\n",
       " ('employer_provided', 'int'),\n",
       " ('min_salary', 'int'),\n",
       " ('max_salary', 'int'),\n",
       " ('avg_salary', 'double'),\n",
       " ('company_txt', 'string'),\n",
       " ('job_state', 'string'),\n",
       " ('python_yn', 'int'),\n",
       " ('R_yn', 'int'),\n",
       " ('spark', 'int'),\n",
       " ('aws', 'int'),\n",
       " ('excel', 'int'),\n",
       " ('job_simp', 'string'),\n",
       " ('seniority', 'string'),\n",
       " ('desc_len', 'int'),\n",
       " ('num_comp', 'int')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa74b18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-----------------+------------------+--------------------+----------+----------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+---------+------------------+--------------------+-------------------+-------------------+------------------+--------+---------+------------------+------------------+\n",
      "|summary|                ID|        Job Title|            Rating|        Location|       Headquarters|             Size|           Founded|   Type of ownership|  Industry|          Sector|             Revenue|              hourly|   employer_provided|        min_salary|        max_salary|        avg_salary|         company_txt|job_state|         python_yn|                R_yn|              spark|                aws|             excel|job_simp|seniority|          desc_len|          num_comp|\n",
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-----------------+------------------+--------------------+----------+----------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+---------+------------------+--------------------+-------------------+-------------------+------------------+--------+---------+------------------+------------------+\n",
      "|  count|               741|              741|               741|             741|                741|              741|               741|                 741|       741|             741|                 741|                 741|                 741|               741|               741|               741|                 741|      741|               741|                 741|                741|                741|               741|     741|      741|               741|               741|\n",
      "|   mean| 370.2159244264507|             NULL| 3.679082321187588|            NULL|               NULL|             NULL|1971.4264507422401|                NULL|      NULL|            -1.0|                NULL|0.032388663967611336|0.021592442645074223|  74.6855600539811|  128.140350877193|100.60323886639677|                NULL|     NULL|0.5290148448043185|0.002699055330634278| 0.2253711201079622|0.23751686909581646|0.5222672064777328|    NULL|     NULL|3870.1295546558704|1.0553306342780027|\n",
      "| stddev|214.34619462793214|             NULL|0.5720349828397239|            NULL|               NULL|             NULL|52.554595056711584|                NULL|      NULL|             0.0|                NULL|  0.1771496239813286|  0.1454467531327641|30.987568027957078|45.250166544546005| 38.87723839435158|                NULL|     NULL|0.4994945835227074| 0.05191731848396881|0.41810871297729174|0.42584896294587343|0.4998413141338195|    NULL|     NULL|1522.4404135868954|1.3846315950630184|\n",
      "|    min|                 0|Ag Data Scientist|               1.9|Agoura Hills, CA|          Akron, OH|1 to 50 employees|              1744|College / University|Accounting|              -1|$1 to $2 billion ...|                   0|                   0|                15|                16|              13.5|1-800-FLOWERS.COM...|       AL|                 0|                   0|                  0|                  0|                 0| analyst|       jr|               407|                 0|\n",
      "|    max|               741| Web Data Analyst|               5.0|   Worcester, MA|Zurich, Switzerland|          Unknown|              2019|             Unknown| Wholesale|Travel & Tourism|Unknown / Non-App...|                   1|                   1|               202|               306|             254.0|           webfx.com|       WI|                 1|                   1|                  1|                  1|                 1|   vague|   senior|             10051|                 4|\n",
      "+-------+------------------+-----------------+------------------+----------------+-------------------+-----------------+------------------+--------------------+----------+----------------+--------------------+--------------------+--------------------+------------------+------------------+------------------+--------------------+---------+------------------+--------------------+-------------------+-------------------+------------------+--------+---------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491f516",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "TODO: find good relation ships for regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c6cb899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 622 -- Test size: 119\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "train_df, test_df = df.randomSplit(weights=[0.8,0.2], seed=seed)\n",
    "print('Train size:', train_df.count(), '-- Test size:', test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657ada9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
